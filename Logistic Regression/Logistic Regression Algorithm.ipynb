{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFXZug066bJX"
   },
   "source": [
    "# Upload files in Google Colab\n",
    "If you are running this Jupyter Notebook on Google Colab, run this cell to upload the data files (train_inputs.csv, train_targets.csv, test_inputs.csv, test_targets.csv) in the colab virtual machine.  You will be prompted to select files that you would like to upload. \n",
    "\n",
    "If you are running this Jupyter Notebook on your computer, you do not need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "dqBJV_Br4XeI",
    "outputId": "ca0e111b-2278-41ab-c548-d86d4efcd023"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f7f77c20-e825-4b95-bb4f-1e7e5059908c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-f7f77c20-e825-4b95-bb4f-1e7e5059908c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_inputs.csv to test_inputs.csv\n",
      "Saving test_labels.csv to test_labels.csv\n",
      "Saving train_inputs.csv to train_inputs.csv\n",
      "Saving train_labels.csv to train_labels.csv\n",
      "\u001b[0m\u001b[01;34msample_data\u001b[0m/     test_labels.csv   train_labels.csv\n",
      "test_inputs.csv  train_inputs.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZDpxE4jmFwA"
   },
   "source": [
    "# Import libraries \n",
    "Do not use any other Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m_1d0BPfmacB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6keYhcgi7nbf"
   },
   "source": [
    "# Function: load_logistic_regression_data\n",
    "\n",
    "This function loads the data for Logistic Regression from a local drive into RAM\n",
    "\n",
    "Outputs:\n",
    "\n",
    "*   **train_inputs**: numpy array of N training data points x M features\n",
    "*   **train_labels**: numpy array of N training labels\n",
    "*   **test_inputs**: numpy array of N' test data points x M features\n",
    "*   **test_labels**: numpy array of N' test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vcG5U2lR7utt"
   },
   "outputs": [],
   "source": [
    "def load_logistic_regression_data():\n",
    "  test_inputs = np.genfromtxt('test_inputs.csv', delimiter=',')\n",
    "  test_labels = np.genfromtxt('test_labels.csv', delimiter=',')\n",
    "  train_inputs = np.genfromtxt('train_inputs.csv', delimiter=',')\n",
    "  train_labels = np.genfromtxt('train_labels.csv', delimiter=',')\n",
    "  return train_inputs, train_labels, test_inputs, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZTxUMDM2PDx"
   },
   "source": [
    "# Function: sigmoid\n",
    "\n",
    "This function implements the logistic sigmoid.\n",
    "\n",
    "Input:\n",
    "*   **input**: vector of inputs (numpy array of floats)\n",
    "\n",
    "Output:\n",
    "*   **output**: vector of outputs (numpy array of floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "evR9GYnV3FmM"
   },
   "outputs": [],
   "source": [
    "def sigmoid(input):\n",
    "  output = 1/(1 + np.exp(-input))\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwLo3p4f8bTa"
   },
   "source": [
    "# Function: predict_logistic_regression\n",
    "\n",
    "This function uses a vector of weights to make predictions for a set of inputs.  The prediction for each data point is a distribution over the labels.  Assume that there are only two possible labels {0,1}.\n",
    "\n",
    "Inputs:\n",
    "*   **inputs**: matrix of input data points for which we want to make a prediction (numpy array of N data points x M+1 features)\n",
    "*   **weights**: vector of weights (numpy array of M+1 weights)\n",
    "\n",
    "Output:\n",
    "*   **predicted_probabilities**: matrix of predicted probabilities (numpy array of N data points x 2 labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iX04_wClRqkV"
   },
   "outputs": [],
   "source": [
    "def predict_logistic_regression(inputs, weights):\n",
    "  probabilities = sigmoid(np.dot(weights, inputs.T)) \n",
    "  predicted_probabilities = np.array([probabilities, 1-probabilities]).T\n",
    "  return predicted_probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmfPN7K0RtQ5"
   },
   "source": [
    "# Function eval_logistic_regression\n",
    "\n",
    "This function evaluates a set of predictions by computing the negative log probabilities of the labels and the accuracy (percentage of correctly predicted labels).  Assume that there are only two possible labels {0,1}.  A data point is correctly labeled when the probability of the target label is >= 0.5.\n",
    "\n",
    "Inputs:\n",
    "*   **inputs**: matrix of input data points for which we will evaluate the predictions (numpy array of N data points x M+1 features)\n",
    "*   **weights**: vector of weights (numpy array of M+1 weights)\n",
    "*   **labels**: vector of target labels associated with the inputs (numpy array of N labels)\n",
    "\n",
    "Outputs:\n",
    "*   **neg_log_prob**: negative log probability of the set of predictions (float)\n",
    "*   **accuracy**: percentage of correctly labeled data points (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wC14LEsvTxbu"
   },
   "outputs": [],
   "source": [
    "def eval_logistic_regression(inputs, weights, labels):\n",
    "  predicted_labels = np.log(predict_logistic_regression(inputs, weights))\n",
    "  accurate_labels = predict_logistic_regression(inputs, weights)\n",
    "  accuracy = (np.count_nonzero(accurate_labels >= 0.5) / len(labels)) * 100\n",
    "\n",
    "  neg_log_prob = 0\n",
    "\n",
    "  for i in range(len(labels)):\n",
    "    neg_log_prob += (labels[i]*predicted_labels[i,0]) + ((1-labels[i])* predicted_labels[i,1])\n",
    "\n",
    "  return -neg_log_prob, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7hZ4XVP4U4y"
   },
   "source": [
    "# Function: initialize_weights\n",
    "\n",
    "This function initializes the weights uniformly at random in the interval [-0.01,0.01]\n",
    "\n",
    "Input:\n",
    "*   **n_weights**: # of weights to be initialized (integer)\n",
    "\n",
    "Output:\n",
    "*   **random_weights**: vector of weights (numpy array of floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9OjhevpV5FBg"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(n_weights):\n",
    "  random_weights = np.random.uniform(-0.01,0.01,n_weights)\n",
    "  return random_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMAzC5xXT0H-"
   },
   "source": [
    "# Function train_logistic_regression_gradient\n",
    "\n",
    "This function optimizes a set of weights for logistic regression based on a training set.  Initialize the weights with the function initialize_weights.  Implement gradient descent to optimize the weights.  Stop the algorithm when the Euclidean norm of the gradient is less than gradient_norm_threshold=0.1 or the number of iterations (i.e., gradient updates) reaches max_iters=10000.  Use learning_rate=0.0001. Assume that there are only two labels {0,1}.\n",
    "\n",
    "Inputs:\n",
    "*   **train_inputs**: matrix of input training points (numpy array of N data points x M+1 features)\n",
    "*   **train_labels**: vector of labels associated with the inputs (numpy array of N labels)\n",
    "*   **lambda_hyperparam**: lambda hyperparameter used to adjust the importance of the regularizer (scalar)\n",
    "*   **max_iters**: maximum number of iterations (i.e., number of weight updates) (default=10000)\n",
    "*   **gradient_norm_threshold**: threshold for the Euclidean norm of the gradient.  When the norm of the gradient falls below this threshold, the algorithm is stopped. (default=0.1)\n",
    "*   **learning_rate**: learning rate that that multiplies the gradient in a weight update (default=0.0001)\n",
    "\n",
    "Output:\n",
    "*   **weights**: vector of weights that have been optimized (numpy array of M+1 weights)\n",
    "*   **n_iters**: number of iterations (i.e., number of weight updates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_DkzoT5QVy41"
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression_gradient(train_inputs, train_labels, lambda_hyperparam, max_iters=10000, gradient_norm_threshold=0.1, learning_rate=0.0001):\n",
    "  i = 0\n",
    "  gradient_norm = gradient_norm_threshold + 1\n",
    "  weights = initialize_weights(train_inputs.shape[1])\n",
    "  \n",
    "  while i <= max_iters and gradient_norm > gradient_norm_threshold:\n",
    "    predicted_labels = predict_logistic_regression(train_inputs, weights)\n",
    "    error_margin =  predicted_labels[:, 0] - train_labels\n",
    "    \n",
    "    gradient = np.dot(error_margin.T, train_inputs) + lambda_hyperparam * weights\n",
    "    gradient_norm = np.linalg.norm(gradient)\n",
    "    \n",
    "    weights -= learning_rate * gradient\n",
    "    i += 1\n",
    "  return weights, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPmXbYggOzOf"
   },
   "source": [
    "# Function train_logistic_regression_newton\n",
    "\n",
    "This function optimizes a set of weights for logistic regression based on a training set.  Initialize the weights with the function initialize_weights.  Implement Newton's algorithm to optimize the weights.  Stop the algorithm when the Euclidean norm of the gradient is less than gradient_norm_threshold=0.1 or the number of iterations (i.e., weight updates) reaches max_iters=10000. Assume that there are only two labels {0,1}.\n",
    "\n",
    "Inputs:\n",
    "*   **train_inputs**: matrix of input training points (numpy array of N data points x M+1 features)\n",
    "*   **train_labels**: vector of labels associated with the inputs (numpy array of N labels)\n",
    "*   **lambda_hyperparam**: lambda hyperparameter used to adjust the importance of the regularizer (scalar)\n",
    "*   **max_iters**: maximum number of iterations (i.e., number of weight updates) (default=10000)\n",
    "*   **gradient_norm_threshold**: threshold for the Euclidean norm of the gradient.  When the norm of the gradient falls below this threshold, the algorithm is stopped. (default=0.1)\n",
    "\n",
    "Output:\n",
    "*   **weights**: vector of weights that have been optimized (numpy array of M+1 weights)\n",
    "*   **n_iters**: number of iterations (i.e., number of weight updates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cXCPk6WRPBGw"
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression_newton(train_inputs, train_labels, lambda_hyperparam, max_iters=10000, gradient_norm_threshold=0.1):\n",
    "  i = 0 \n",
    "  gradient_norm = gradient_norm_threshold + 1\n",
    "  weights = initialize_weights(train_inputs.shape[1])\n",
    "  \n",
    "  while i <= max_iters and gradient_norm > gradient_norm_threshold:\n",
    "    predicted_labels = predict_logistic_regression(train_inputs, weights)\n",
    "    error_margin =  predicted_labels[:, 0] - train_labels\n",
    "    \n",
    "    gradient =  np.dot(error_margin.T, train_inputs) + lambda_hyperparam * weights\n",
    "    gradient_norm = np.linalg.norm(gradient)\n",
    "    r = np.identity(train_inputs.shape[0])\n",
    "    \n",
    "    for i in range(train_inputs.shape[0]):\n",
    "      r[i, i] = predicted_labels[i, 0] * predicted_labels[i, 1] \n",
    "    \n",
    "    hessian = np.dot(train_inputs.T, np.dot(r, train_inputs)) + lambda_hyperparam * np.identity(train_inputs.shape[1])\n",
    "    weights -= np.dot(np.linalg.inv(hessian), gradient)\n",
    "    i += 1\n",
    "\n",
    "  return weights, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYIbLxX7V2DW"
   },
   "source": [
    "# Function cross_validation_logistic_regression\n",
    "\n",
    "This function performs k-fold cross validation to determine the best lambda hyperparameter in logistic regression\n",
    "\n",
    "Inputs:\n",
    "*   **k_folds**: # of folds in cross-validation (integer)\n",
    "*   **hyperparameters**: list of hyperparameters where each hyperparameter is a different lambda value (list of floats)\n",
    "*   **inputs**: matrix of input points (numpy array of N data points by M+1 features)\n",
    "*   **labels**: vector of labels associated with the inputs (numpy array of N labels)\n",
    "*   **algorithm**: string in {'newton','gradient descent'}\n",
    "\n",
    "Outputs:\n",
    "*   **best_hyperparam**: best lambda value for logistic regression (float)\n",
    "*   **best_neg_log_prob**: negative log probabilty achieved with best_hyperparam (float)\n",
    "*   **neg_log_probabilities**: vector of negative log probabilities for the corresponding hyperparameters (numpy array of floats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_ZzoiZxLZMcV"
   },
   "outputs": [],
   "source": [
    "def cross_validation_logistic_regression(k_folds, hyperparameters, inputs, labels, algorithm):\n",
    "  label = np.array_split(labels, k_folds)\n",
    "  fold = np.array_split(inputs, k_folds)\n",
    "  neg_log_prob = np.array([])\n",
    "  \n",
    "  for hyper in hyperparameters:\n",
    "    h_parameter_nl = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for i in range (k_folds):\n",
    "      test_inputs = fold[i]\n",
    "      test_labels = label[i]\n",
    "      train_inputs = np.concatenate([fold[j] for j in range (k_folds) if j != i])\n",
    "      train_labels = np.concatenate([label[j] for j in range (k_folds) if j != i])\n",
    "\n",
    "      if algorithm == \"gradient descent\":\n",
    "        [weights, n_iter] = train_logistic_regression_gradient(train_inputs, train_labels, hyper, 10000, 0.1, 0.0001)\n",
    "      elif algorithm == \"newton\":  \n",
    "        [weights, n_iter] = train_logistic_regression_newton(train_inputs, train_labels, hyper, 10000, 0.1)\n",
    "      else:\n",
    "        raise ValueError('Invalid algorithm: {}. Only \"newton\" and \"gradient descent\" are allowed.'.format(algorithm))   \n",
    "\n",
    "      [nl, accuracy] = eval_logistic_regression(test_inputs, weights, test_labels)\n",
    "      h_parameter_nl += nl\n",
    "\n",
    "    neg_log_prob = np.append(neg_log_prob, h_parameter_nl/k_folds)\n",
    "  \n",
    "  a = neg_log_prob.argmin()\n",
    "  best_hyperparam = hyperparameters[a]\n",
    "  best_neg_log_prob = neg_log_prob[a]\n",
    "  neg_log_probabilities = neg_log_prob\n",
    "  return best_hyperparam, best_neg_log_prob, neg_log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ah5AAayZfVU"
   },
   "source": [
    "# Function: plot_logistic_regression_neg_log_probabilities\n",
    "\n",
    "Function that plots the negative log probabilities for different lambda values (hyperparameters) in logistic regression based on cross validation\n",
    "\n",
    "Inputs:\n",
    "*   **neg_log_probabilities**: vector of negative log probabilities for the corresponding hyperparameters (numpy array of floats)\n",
    "*   **hyperparams**: list of hyperparameters where each hyperparameter is a different lambda value (list of floats)\n",
    "*   **algorithm**: string in {'newton','gradient descent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dh9qZuzMatsZ"
   },
   "outputs": [],
   "source": [
    "def plot_logistic_regression_neg_log_probabilities(neg_log_probabilities,hyperparams,algorithm):\n",
    "  plt.plot(hyperparams,neg_log_probabilities)\n",
    "  plt.ylabel('negative log probability')\n",
    "  plt.xlabel('lambda')\n",
    "  plt.title(algorithm)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s21LRP5Qb3m8"
   },
   "source": [
    "# Main Logistic Regression code\n",
    "\n",
    "Load data (rescale the inputs to be in the [-1,1] range, add 1 at the end of each datapoint and rename the labels 5,6 to 0,1).\n",
    "Use k-fold cross validation to find the best lambda value for logistic regression.\n",
    "Plot the negative log probabilities for different lambda values.\n",
    "Test logistic regression with the best lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "id": "njlK2bf7sycQ",
    "outputId": "4af2b5cd-1c8d-4874-ec33-8f5d66db3457"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent best lambda: 8\n",
      "Gradient descent best cross validation negative log probability: 37.60475915995886\n",
      "Gradient descent test accuracy: 100.0\n",
      "Gradient descent test negative log probability: 33.285738454642704\n",
      "Gradient descent # of iterations: 3101\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton best lambda: 8\n",
      "Newton best cross validation negative log probability: 37.60806442833481\n",
      "Newton test accuracy: 100.0\n",
      "Newton test negative log probability: 33.29203077371129\n",
      "Newton # of iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_inputs, train_labels, test_inputs, test_labels = load_logistic_regression_data()\n",
    "\n",
    "# rescale inputs in the [-1,1] range\n",
    "train_inputs = (train_inputs - 8)/8\n",
    "test_inputs = (test_inputs - 8)/8\n",
    "\n",
    "# add 1 at the end of each data point\n",
    "train_inputs = np.concatenate((train_inputs,np.ones((train_inputs.shape[0],1))),1)\n",
    "test_inputs = np.concatenate((test_inputs,np.ones((test_inputs.shape[0],1))),1)\n",
    "\n",
    "# rename the classes 5,6 to 0,1\n",
    "train_labels = train_labels.astype(int) - 5\n",
    "test_labels = test_labels.astype(int) - 5\n",
    "\n",
    "###############################################\n",
    "# logistic regression based on gradient descent\n",
    "###############################################\n",
    "\n",
    "# lambda values to be evaluated by cross validation\n",
    "hyperparams = range(26)\n",
    "k_folds = 10\n",
    "best_lambda, best_neg_log_prob, neg_log_probabilities = cross_validation_logistic_regression(k_folds,hyperparams,train_inputs,train_labels,'gradient descent')\n",
    "\n",
    "# plot results\n",
    "plot_logistic_regression_neg_log_probabilities(neg_log_probabilities,hyperparams,'gradient descent')\n",
    "print('Gradient descent best lambda: ' + str(best_lambda))\n",
    "print('Gradient descent best cross validation negative log probability: ' + str(best_neg_log_prob))\n",
    "\n",
    "# train and evaluate with best lambda\n",
    "weights, n_iters = train_logistic_regression_gradient(train_inputs,train_labels,best_lambda)\n",
    "neg_log_prob, accuracy = eval_logistic_regression(test_inputs, weights, test_labels)\n",
    "print('Gradient descent test accuracy: ' + str(accuracy))\n",
    "print('Gradient descent test negative log probability: ' + str(neg_log_prob))\n",
    "print('Gradient descent # of iterations: ' + str(n_iters))\n",
    "\n",
    "#################################################\n",
    "# logistic regression based on Newton's algorithm\n",
    "#################################################\n",
    "\n",
    "# lambda values to be evaluated by cross validation\n",
    "hyperparams = range(26)\n",
    "k_folds = 10\n",
    "best_lambda, best_neg_log_prob, neg_log_probabilities = cross_validation_logistic_regression(k_folds,hyperparams,train_inputs,train_labels,'newton')\n",
    "\n",
    "# plot results\n",
    "plot_logistic_regression_neg_log_probabilities(neg_log_probabilities,hyperparams,'newton')\n",
    "print('Newton best lambda: ' + str(best_lambda))\n",
    "print('Newton best cross validation negative log probability: ' + str(best_neg_log_prob))\n",
    "\n",
    "# train and evaluate with best lambda\n",
    "weights, n_iters = train_logistic_regression_newton(train_inputs,train_labels,best_lambda)\n",
    "neg_log_prob, accuracy = eval_logistic_regression(test_inputs, weights, test_labels)\n",
    "print('Newton test accuracy: ' + str(accuracy))\n",
    "print('Newton test negative log probability: ' + str(neg_log_prob))\n",
    "print('Newton # of iterations: ' + str(n_iters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrZ89HrA9dBO"
   },
   "source": [
    "**Question 1:**\n",
    "Gradient Decent Algorithm has a time complexity    \n",
    "O(n) 'linear time' and a space complexity of O(1) 'constant time'. Best case applications would be for linear regression problems with large datasets because of its simplicity and computational efficency\n",
    "\n",
    "Newton's Algorithm would typically have a time complexity of O(d^3) 'cubic time' with d being the number of dimensions and a space complexity of O(d^2) 'quadratic time'. This would be best applied on linear regression problems where the cost function is smooth and the gradient and hessian can be easily computed.\n",
    "\n",
    "**Question 2:**\n",
    "Logistic regression find a linear sperator menaing it finds the best hyperplane to seperate data into classes. Where as KNN finds a non-linear seperator by using the majority class of the k nearest neighbors for a given datapoint.\n",
    "\n",
    "The performance for each seperator depends on the given dataset where logostic regression would perform best when the features and target relationship is linear. KNN does the opposite and perfroms best when the relationship is non-linear, while it can handle any type of data it is computationally expensive to interpret other types of data.\n",
    "\n",
    "**Question 3:**\n",
    "The plot_boundary function in the code creates a meshgrid of x and y values and then calculates a boundary between two classes based on the weights and bias of the logistic regression model. If the boundary separates the two classes well, it suggests that the classes are linearly separable. The visualization of the boundary can give you an idea of how well the model is separating the two classes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfOW3T4yH6yW"
   },
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "# Load your dataset\n",
    "train_inputs, train_labels, test_inputs, test_labels = load_logistic_regression_data()\n",
    "\n",
    "X = train_inputs \n",
    "y = train_labels\n",
    "\n",
    "# Fit a logistic regression model\n",
    "weights = np.zeros(X.shape[1])  # Initialize weights\n",
    "#weights = weights.reshape(-1, 1)\n",
    "bias = 0  # Initialize bias\n",
    "learning_rate = 0.01  # Set learning rate\n",
    "\n",
    "# Train the model using gradient descent\n",
    "for i in range(100):\n",
    "    # Calculate the predicted probabilities for each data point\n",
    "    z = X.dot(weights) + bias\n",
    "    predictions = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # Calculate the error for each data point\n",
    "    error = predictions - y\n",
    "\n",
    "    # Update the weights and bias using gradient descent\n",
    "    weights = weights - learning_rate * X.T.dot(error)\n",
    "    bias = bias - learning_rate * np.sum(error)\n",
    "\n",
    "# Plot the data and the decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "weights = weights.reshape(-1,1)\n",
    "z = grid.dot(weights.shape)\n",
    "probs = 1 / (1 + np.exp(-z))\n",
    "probs = probs.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, probs, alpha=0.3)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', marker='o', label='class 0')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', marker='x', label='class 1')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
